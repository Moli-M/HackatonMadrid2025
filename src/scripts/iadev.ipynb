{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selección de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 68.20\n",
      "R²: 0.80\n",
      "\n",
      "Características más importantes:\n",
      "Característica 3088: 0.2454\n",
      "Característica 3093: 0.1605\n",
      "Característica 4: 0.1462\n",
      "Característica 5: 0.1148\n",
      "Característica 3090: 0.1035\n",
      "Característica 3091: 0.0838\n",
      "Característica 6: 0.0182\n",
      "Característica 3089: 0.0152\n",
      "Característica 7: 0.0107\n",
      "Característica 3092: 0.0037\n",
      "\n",
      "MSE without BERT: 59.78\n",
      "R² without BERT: 0.82\n",
      "================================================\n",
      "================================================\n",
      "================================================\n",
      "\n",
      "Resultados de validación con ejemplos nuevos:\n",
      "  category                                            summary  \\\n",
      "0  Fintech  Plataforma de gestión financiera personal con ...   \n",
      "1  Fintech  Seguro paramétrico basado en blockchain para p...   \n",
      "2  Energía  Sistema de almacenamiento de energía basado en...   \n",
      "3  Energía  Plataforma de comercio de energía P2P para com...   \n",
      "4    Salud  Plataforma de diagnóstico remoto para zonas ru...   \n",
      "\n",
      "   actual_viability  predicted_viability  \n",
      "0        100.000000            94.200785  \n",
      "1         55.185984            58.402229  \n",
      "2         86.927590            68.519934  \n",
      "3         86.868436            81.457911  \n",
      "4         95.000000            85.734335  \n",
      "\n",
      "MSE en ejemplos de validación: 91.28\n",
      "R² en ejemplos de validación: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Importación de bibliotecas necesarias\n",
    "import pandas as pd  # Para manipulación y análisis de datos estructurados\n",
    "import numpy as np  # Para operaciones numéricas\n",
    "import random  # Para generar números aleatorios\n",
    "from sklearn.model_selection import train_test_split  # Para dividir datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Para preprocesamiento de datos\n",
    "from sklearn.ensemble import RandomForestRegressor  # Algoritmo de regresión basado en árboles de decisión\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Métricas para evaluar el rendimiento del modelo\n",
    "from transformers import BertTokenizer, BertModel  # Modelo BERT para procesamiento de lenguaje natural\n",
    "import torch  # Framework para redes neuronales y computación tensorial\n",
    "\n",
    "# Cargar modelo y tokenizer de BERT\n",
    "# BERT es un modelo preentrenado de lenguaje natural desarrollado por Google\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # Convierte texto en tokens que BERT puede procesar\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')  # Modelo que genera representaciones contextuales de texto\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    \"\"\"Convierte una lista de textos en embeddings de BERT.\n",
    "    \n",
    "    Los embeddings son representaciones numéricas de texto que capturan significado semántico.\n",
    "    BERT produce embeddings contextuales de 768 dimensiones por token.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=128)\n",
    "    with torch.no_grad():  # Desactivamos cálculo de gradientes para ahorrar memoria\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # Extraemos solo el embedding del token [CLS]\n",
    "\n",
    "# Ejemplos de proyectos por categoría\n",
    "# Este diccionario contiene datos estructurados para ejemplos de proyectos en diferentes sectores\n",
    "# Cada proyecto tiene un resumen, problema que aborda, solución propuesta y diferenciación\n",
    "project_details = {\n",
    "    'Tech': [\n",
    "        {\n",
    "            'summary': \"Plataforma de pagos transfronterizos que facilita la transferencia de dinero de manera rápida y segura.\",\n",
    "            'problem_addressed': \"Los pagos internacionales son costosos y lentos, afectando a las pequeñas empresas.\",\n",
    "            'solution_proposed': \"Solución que ofrece tarifas de pago transfronterizas reducidas y procesamiento rápido, utilizando blockchain.\",\n",
    "            'differentiation': \"Utiliza una red de blockchain descentralizada para garantizar la transparencia y baja de costos en pagos.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Aplicación de microinversiones que permite a usuarios invertir pequeñas cantidades en bolsa.\",\n",
    "            'problem_addressed': \"El acceso a inversiones en bolsa requiere capital inicial alto y conocimientos financieros avanzados.\",\n",
    "            'solution_proposed': \"Plataforma que permite inversiones desde 1€ y automatiza decisiones basadas en perfiles de riesgo.\",\n",
    "            'differentiation': \"Interfaz intuitiva con recomendaciones personalizadas basadas en machine learning.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Plataforma de préstamos P2P que conecta directamente a prestatarios con inversores.\",\n",
    "            'problem_addressed': \"Dificultad para acceder a créditos por parte de pequeños emprendedores y altas tasas de interés bancarias.\",\n",
    "            'solution_proposed': \"Sistema que evalúa el riesgo crediticio mediante IA y conecta con inversores dispuestos a financiar.\",\n",
    "            'differentiation': \"Evaluación de riesgo basada en datos alternativos más allá del historial crediticio tradicional.\"\n",
    "        }\n",
    "    ],\n",
    "    'Energía': [\n",
    "        {\n",
    "            'summary': \"Desarrollo de un sistema de energía solar de bajo costo para hogares en zonas rurales.\",\n",
    "            'problem_addressed': \"El acceso a energía limpia en zonas rurales es limitado y costoso.\",\n",
    "            'solution_proposed': \"Sistema de paneles solares con batería de almacenamiento que reduce el costo de energía en áreas rurales.\",\n",
    "            'differentiation': \"Baterías solares desarrolladas con tecnología avanzada que optimizan la eficiencia en lugares remotos.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Red inteligente para optimización del consumo eléctrico en edificios comerciales.\",\n",
    "            'problem_addressed': \"El desperdicio energético en grandes edificios genera altos costos y emisiones innecesarias.\",\n",
    "            'solution_proposed': \"Sistema IoT que monitoriza y ajusta automáticamente el consumo energético según uso y ocupación.\",\n",
    "            'differentiation': \"Algoritmos predictivos que anticipan necesidades energéticas y reducen consumo hasta un 40%.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Generadores eólicos de pequeña escala para entornos urbanos.\",\n",
    "            'problem_addressed': \"Las energías renovables como la eólica no están adaptadas para uso en ciudades y espacios residenciales.\",\n",
    "            'solution_proposed': \"Microturbinas eólicas que se adaptan a edificios y generan electricidad con vientos de baja intensidad.\",\n",
    "            'differentiation': \"Diseño silencioso y estético que permite su instalación en zonas residenciales sin impacto visual.\"\n",
    "        }\n",
    "    ],\n",
    "    'Salud': [\n",
    "        {\n",
    "            'summary': \"Aplicación de telemedicina que conecta a pacientes con médicos especializados en tiempo real.\",\n",
    "            'problem_addressed': \"El acceso a atención médica de calidad en zonas remotas es insuficiente.\",\n",
    "            'solution_proposed': \"Aplicación que permite consultas médicas en línea, reduciendo los tiempos de espera y costos de consulta.\",\n",
    "            'differentiation': \"Ofrece consultas médicas en línea las 24 horas, sin necesidad de desplazamientos.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Dispositivo wearable para monitorización continua de pacientes con enfermedades crónicas.\",\n",
    "            'problem_addressed': \"El seguimiento de pacientes crónicos es costoso y requiere visitas frecuentes a centros médicos.\",\n",
    "            'solution_proposed': \"Dispositivo no invasivo que monitoriza constantes vitales y envía alertas automáticas a médicos.\",\n",
    "            'differentiation': \"Integra sensores avanzados con IA para detectar anomalías antes de que se conviertan en emergencias.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Sistema de diagnóstico por imagen asistido por IA para detección temprana de cáncer.\",\n",
    "            'problem_addressed': \"El diagnóstico tardío de diversos tipos de cáncer reduce significativamente las tasas de supervivencia.\",\n",
    "            'solution_proposed': \"Software que analiza imágenes médicas y detecta patrones sospechosos con mayor precisión que métodos tradicionales.\",\n",
    "            'differentiation': \"Algoritmo entrenado con millones de imágenes que supera en un 30% la precisión de diagnósticos humanos.\"\n",
    "        }\n",
    "    ],\n",
    "    'Educación': [\n",
    "        {\n",
    "            'summary': \"Herramienta educativa basada en IA para personalizar los métodos de enseñanza según el perfil del estudiante.\",\n",
    "            'problem_addressed': \"El sistema educativo no está personalizado y no responde a las necesidades individuales de los estudiantes.\",\n",
    "            'solution_proposed': \"Plataforma educativa basada en IA que adapta los contenidos a las necesidades y ritmo del estudiante.\",\n",
    "            'differentiation': \"Personaliza el aprendizaje mediante algoritmos que se ajustan a la forma de aprender del estudiante.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Plataforma de aprendizaje de idiomas mediante realidad virtual inmersiva.\",\n",
    "            'problem_addressed': \"Los métodos tradicionales de aprendizaje de idiomas no logran contextos reales de práctica conversacional.\",\n",
    "            'solution_proposed': \"Experiencias de realidad virtual que simulan entornos reales para practicar idiomas con nativos virtuales.\",\n",
    "            'differentiation': \"Tecnología de reconocimiento de voz que analiza la pronunciación y ofrece correcciones en tiempo real.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Sistema de microcredenciales digitales para validar habilidades profesionales específicas.\",\n",
    "            'problem_addressed': \"La brecha entre educación formal y habilidades requeridas en el mercado laboral actual.\",\n",
    "            'solution_proposed': \"Plataforma que certifica habilidades específicas mediante pruebas prácticas verificadas por empleadores.\",\n",
    "            'differentiation': \"Credenciales basadas en blockchain que son inmutables y verificables instantáneamente por reclutadores.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generación de datos sintéticos con ejemplos reales\n",
    "def generate_synthetic_data(n=500):\n",
    "    \"\"\"\n",
    "    Genera un conjunto de datos sintéticos de proyectos basados en los ejemplos reales.\n",
    "    \n",
    "    Args:\n",
    "        n: Número de muestras a generar (por defecto 500)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con datos sintéticos de proyectos y sus características\n",
    "    \"\"\"\n",
    "    # Definición de valores posibles para variables categóricas\n",
    "    categories = ['Tech', 'Energía', 'Salud', 'Educación']\n",
    "    stages = ['Idea', 'Prototipo', 'MVP', 'Escalando']\n",
    "    asset_types = ['Equity', 'Deuda', 'Otro']\n",
    "    legal_statuses = ['Regulado', 'No regulado']\n",
    "    impact_types = ['Social', 'Ambiental', 'Económico']\n",
    "    \n",
    "    # Listas para almacenar los datos generados\n",
    "    category_list = []\n",
    "    summary_list = []\n",
    "    problem_list = []\n",
    "    solution_list = []\n",
    "    differentiation_list = []\n",
    "    \n",
    "    # Generar datos basados en ejemplos reales\n",
    "    for _ in range(n):\n",
    "        # Seleccionar una categoría aleatoria \n",
    "        category = np.random.choice(categories)\n",
    "        category_list.append(category)\n",
    "        \n",
    "        # Obtener la lista de proyectos disponibles para esta categoría\n",
    "        available_projects = project_details[category]\n",
    "        # Seleccionar aleatoriamente un proyecto específico de esta categoría\n",
    "        example = random.choice(available_projects)\n",
    "        \n",
    "        # Extraer textos del ejemplo seleccionado\n",
    "        summary_list.append(example['summary'])\n",
    "        problem_list.append(example['problem_addressed'])\n",
    "        solution_list.append(example['solution_proposed'])\n",
    "        \n",
    "        # Verificar y extraer diferenciación si existe\n",
    "        if 'differentiation' in example:\n",
    "            differentiation_list.append(example['differentiation'])\n",
    "        else:\n",
    "            differentiation_list.append(\"Ventaja competitiva en el mercado\")\n",
    "    \n",
    "    # Crear DataFrame con todos los datos\n",
    "    data = pd.DataFrame({\n",
    "        'category': category_list,\n",
    "        'stage': np.random.choice(stages, n),  # Etapa del proyecto (aleatoria)\n",
    "        'summary': summary_list,\n",
    "        'problem_addressed': problem_list,\n",
    "        'solution_proposed': solution_list,\n",
    "        'differentiation': differentiation_list,\n",
    "        'tokenized_asset_type': np.random.choice(asset_types, n),  # Tipo de activo (aleatorio)\n",
    "        'asset_existing': np.random.choice([0, 1], n),  # Si el activo existe o no (binario)\n",
    "        'legal_status': np.random.choice(legal_statuses, n),  # Estado legal (aleatorio)\n",
    "        'estimated_total_cost_eur': np.random.uniform(50000, 1000000, n),  # Costo estimado (aleatorio entre 50k-1M)\n",
    "        'funding_requested_eur': np.random.uniform(10000, 500000, n),  # Financiación solicitada (aleatorio entre 10k-500k)\n",
    "        'expected_annual_revenue_eur': np.random.uniform(20000, 2000000, n),  # Ingresos esperados (aleatorio entre 20k-2M)\n",
    "        'current_clients_or_pilots': np.random.choice([0, 1], n),  # Si tiene clientes actuales (binario)\n",
    "        'scalability_score': np.random.randint(1, 6, n),  # Puntuación de escalabilidad (1-5)\n",
    "        'impact_type': np.random.choice(impact_types, n),  # Tipo de impacto (aleatorio)\n",
    "    })\n",
    "    \n",
    "    # Crear una puntuación de viabilidad más realista basada en las características\n",
    "    # La fórmula combina varios factores que afectan la viabilidad del proyecto:\n",
    "    \n",
    "    # Factor 1: La etapa más avanzada aumenta la viabilidad\n",
    "    stage_score = data['stage'].map({'Idea': 10, 'Prototipo': 20, 'MVP': 30, 'Escalando': 40})\n",
    "    \n",
    "    # Factor 2: La existencia de clientes aumenta la viabilidad\n",
    "    client_score = data['current_clients_or_pilots'] * 15\n",
    "    \n",
    "    # Factor 3: Mayor escalabilidad aumenta la viabilidad\n",
    "    scalability_score = data['scalability_score'] * 5\n",
    "    \n",
    "    # Factor 4: Mejor ratio ingresos/costos aumenta la viabilidad\n",
    "    revenue_ratio = np.clip(data['expected_annual_revenue_eur'] / (data['estimated_total_cost_eur'] + 1), 0, 5) * 7\n",
    "    \n",
    "    # Calcular puntuación final con algo de ruido aleatorio para simular factores desconocidos\n",
    "    data['viability_score'] = stage_score + client_score + scalability_score + revenue_ratio + np.random.normal(0, 5, n)\n",
    "    \n",
    "    # Limitar los valores entre 0 y 100 para mantenerlo en un rango interpretable\n",
    "    data['viability_score'] = np.clip(data['viability_score'], 0, 100)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Crear datos sintéticos para el entrenamiento y evaluación\n",
    "data = generate_synthetic_data()\n",
    "\n",
    "# Separar variables por tipo para aplicar diferentes preprocesamientos\n",
    "categorical_cols = ['category', 'stage', 'tokenized_asset_type', 'legal_status', 'impact_type']  # Variables categóricas\n",
    "text_cols = ['summary', 'problem_addressed', 'solution_proposed', 'differentiation']  # Variables de texto\n",
    "numeric_cols = ['estimated_total_cost_eur', 'funding_requested_eur', 'expected_annual_revenue_eur', 'scalability_score']  # Variables numéricas\n",
    "binary_cols = ['asset_existing', 'current_clients_or_pilots']  # Variables binarias (0/1)\n",
    "\n",
    "# Preprocesamiento de variables categóricas mediante codificación one-hot\n",
    "# One-hot convierte categorías en vectores binarios (ej: ['A','B','C'] -> [1,0,0], [0,1,0], [0,0,1])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "categorical_features = encoder.fit_transform(data[categorical_cols])\n",
    "\n",
    "# Procesar cada columna de texto individualmente usando BERT\n",
    "text_features = []\n",
    "for col in text_cols:\n",
    "    # Obtener embeddings para cada columna de texto\n",
    "    col_embeddings = get_bert_embeddings(data[col].tolist())\n",
    "    text_features.append(col_embeddings)\n",
    "\n",
    "# Concatenar todos los embeddings de texto horizontalmente\n",
    "text_features_combined = np.hstack(text_features)\n",
    "\n",
    "# Normalización de variables numéricas (media 0, desviación estándar 1)\n",
    "# Esto evita que variables con valores grandes dominen sobre otras\n",
    "scaler = StandardScaler()\n",
    "numeric_features = scaler.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Unir todas las características en una matriz X\n",
    "X = np.hstack([categorical_features, text_features_combined, numeric_features, data[binary_cols].values])\n",
    "# La variable objetivo y es la puntuación de viabilidad\n",
    "y = data['viability_score']\n",
    "\n",
    "# Separar datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo Random Forest con hiperparámetros optimizados\n",
    "# Random Forest es un conjunto de árboles de decisión que promedia sus predicciones\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,  # Número de árboles en el bosque\n",
    "    max_depth=15,      # Profundidad máxima de cada árbol\n",
    "    min_samples_split=5,  # Mínimo de muestras para dividir un nodo\n",
    "    min_samples_leaf=2,   # Mínimo de muestras en cada nodo hoja\n",
    "    random_state=42       # Semilla para reproducibilidad\n",
    ")\n",
    "model.fit(X_train, y_train)  # Entrenamiento del modelo\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)  # Predicciones en datos de prueba\n",
    "mse = mean_squared_error(y_test, y_pred)  # Error cuadrático medio (menor es mejor)\n",
    "r2 = r2_score(y_test, y_pred)  # Coeficiente de determinación (mayor es mejor, máx=1)\n",
    "\n",
    "print(f'MSE: {mse:.2f}')  # Muestra el error cuadrático medio\n",
    "print(f'R²: {r2:.2f}')    # Muestra el coeficiente R²\n",
    "\n",
    "# Mostrar importancia de características para interpretar el modelo\n",
    "feature_importances = model.feature_importances_\n",
    "print(\"\\nCaracterísticas más importantes:\")\n",
    "# Mostrar las 10 características más importantes\n",
    "top_n = 10\n",
    "indices = np.argsort(feature_importances)[-top_n:]\n",
    "for i in reversed(indices):\n",
    "    print(f\"Característica {i}: {feature_importances[i]:.4f}\")\n",
    "\n",
    "# Modelo sin BERT para comparación y evaluar el impacto de las características de texto\n",
    "X_without_text = np.hstack([categorical_features, numeric_features, data[binary_cols].values])\n",
    "X_train_without_text, X_test_without_text, y_train_without_text, y_test_without_text = train_test_split(X_without_text, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar segundo modelo sin usar texto\n",
    "model_without_text = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "model_without_text.fit(X_train_without_text, y_train_without_text)\n",
    "\n",
    "# Evaluar el segundo modelo (sin BERT)\n",
    "y_pred_without_text = model_without_text.predict(X_test_without_text)\n",
    "mse_without_text = mean_squared_error(y_test_without_text, y_pred_without_text)\n",
    "r2_without_text = r2_score(y_test_without_text, y_pred_without_text)\n",
    "\n",
    "print(f'\\nMSE without BERT: {mse_without_text:.2f}')\n",
    "print(f'R² without BERT: {r2_without_text:.2f}')\n",
    "\n",
    "print('================================================')\n",
    "print('================================================')\n",
    "print('================================================')\n",
    "\n",
    "# Crear nuevos ejemplos para validación adicional del modelo\n",
    "# Estos ejemplos son diferentes a los de entrenamiento para probar generalización\n",
    "validation_examples = {\n",
    "    'Tech': [\n",
    "        {\n",
    "            'summary': \"Plataforma de gestión financiera personal con inteligencia artificial para optimizar las finanzas del hogar.\",\n",
    "            'problem_addressed': \"La mayoría de las personas no tienen visibilidad clara de sus patrones de gasto ni herramientas para mejorar sus hábitos financieros.\",\n",
    "            'solution_proposed': \"Software que analiza automáticamente los gastos, detecta patrones, y propone estrategias de ahorro personalizadas.\",\n",
    "            'differentiation': \"Algoritmos de IA que predicen futuras dificultades financieras y sugieren acciones preventivas con tres meses de anticipación.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Seguro paramétrico basado en blockchain para pequeños agricultores contra eventos climáticos extremos.\",\n",
    "            'problem_addressed': \"Los agricultores en países en desarrollo carecen de acceso a seguros tradicionales contra desastres naturales que afectan sus cosechas.\",\n",
    "            'solution_proposed': \"Sistema de seguro automático que paga directamente al agricultor cuando sensores meteorológicos registran condiciones extremas.\",\n",
    "            'differentiation': \"Contratos inteligentes que eliminan los trámites de reclamación y reducen costos operativos hasta en un 85%.\"\n",
    "        }\n",
    "    ],\n",
    "    'Energía': [\n",
    "        {\n",
    "            'summary': \"Sistema de almacenamiento de energía basado en hidrogeno verde para comunidades aisladas.\",\n",
    "            'problem_addressed': \"Las comunidades remotas dependen de generadores diésel contaminantes y costosos para su suministro energético.\",\n",
    "            'solution_proposed': \"Instalación que genera hidrógeno mediante electrólisis con energía renovable y lo almacena para uso cuando no hay sol o viento.\",\n",
    "            'differentiation': \"Tecnología de electrolizadores de alta eficiencia que funciona con agua de baja calidad y reduce costos en un 40%.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Plataforma de comercio de energía P2P para comunidades energéticas locales.\",\n",
    "            'problem_addressed': \"Los prosumidores (productores-consumidores) de energía solar no pueden comercializar eficientemente sus excedentes energéticos.\",\n",
    "            'solution_proposed': \"Marketplace digital que permite a vecinos comprar y vender excedentes de energía renovable dentro de su comunidad local.\",\n",
    "            'differentiation': \"Sistema de precios dinámicos basado en IA que maximiza el ahorro para compradores y el beneficio para vendedores.\"\n",
    "        }\n",
    "    ],\n",
    "    'Salud': [\n",
    "        {\n",
    "            'summary': \"Plataforma de diagnóstico remoto para zonas rurales basada en dispositivos médicos portátiles.\",\n",
    "            'problem_addressed': \"Más de 2 mil millones de personas en el mundo carecen de acceso a servicios de diagnóstico médico básico.\",\n",
    "            'solution_proposed': \"Kit que incluye dispositivos de análisis de sangre, ecografía y ECG portátiles conectados a smartphones para telemedicina.\",\n",
    "            'differentiation': \"Tecnología que funciona sin conexión a internet y sincroniza datos cuando hay conectividad, ideal para zonas aisladas.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Sistema de rehabilitación física mediante realidad virtual gamificada para pacientes con movilidad reducida.\",\n",
    "            'problem_addressed': \"La terapia física tradicional tiene baja adherencia por ser repetitiva y dolorosa, retrasando la recuperación.\",\n",
    "            'solution_proposed': \"Juegos de realidad virtual que convierten los ejercicios terapéuticos en experiencias inmersivas y motivadoras.\",\n",
    "            'differentiation': \"Algoritmos que adaptan automáticamente la dificultad basándose en el progreso y biomecánica del paciente.\"\n",
    "        }\n",
    "    ],\n",
    "    'Educación': [\n",
    "        {\n",
    "            'summary': \"Laboratorios virtuales de ciencias para instituciones educativas con recursos limitados.\",\n",
    "            'problem_addressed': \"Millones de estudiantes no tienen acceso a laboratorios científicos para experimentos prácticos esenciales.\",\n",
    "            'solution_proposed': \"Simulaciones interactivas en 3D que replican experimentos científicos complejos accesibles desde cualquier dispositivo.\",\n",
    "            'differentiation': \"Experiencias multiusuario que permiten colaboración en tiempo real entre estudiantes y profesores remotos.\"\n",
    "        },\n",
    "        {\n",
    "            'summary': \"Plataforma de tutoría entre pares con sistema de microcréditos educativos.\",\n",
    "            'problem_addressed': \"El acceso a tutoría personalizada es costoso y está fuera del alcance de muchos estudiantes.\",\n",
    "            'solution_proposed': \"Red que conecta estudiantes avanzados con aquellos que necesitan ayuda, usando un sistema de intercambio de conocimientos.\",\n",
    "            'differentiation': \"Modelo de economía colaborativa educativa donde los estudiantes ganan créditos enseñando y los usan para recibir ayuda.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def validate_model_with_new_examples(model, encoder, scaler, examples):\n",
    "    \"\"\"\n",
    "    Valida el modelo con nuevos ejemplos manualmente creados.\n",
    "    \n",
    "    Esta función preprocesa nuevos ejemplos de la misma manera que los datos de entrenamiento,\n",
    "    y evalúa el rendimiento del modelo en estos ejemplos.\n",
    "    \n",
    "    Args:\n",
    "        model: El modelo entrenado de RandomForest\n",
    "        encoder: El OneHotEncoder ajustado a los datos de entrenamiento\n",
    "        scaler: El StandardScaler ajustado a los datos de entrenamiento\n",
    "        examples: Diccionario con ejemplos nuevos por categoría\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame con las predicciones y detalles de los ejemplos\n",
    "    \"\"\"\n",
    "    # Crear listas para almacenar los datos de validación\n",
    "    rows = []\n",
    "    \n",
    "    # Procesar cada categoría y sus ejemplos\n",
    "    for category, category_examples in examples.items():\n",
    "        for example in category_examples:\n",
    "            # Generar valores sintéticos aleatorios para las variables no textuales\n",
    "            # Esto simula diferentes escenarios para cada proyecto\n",
    "            stage = np.random.choice(['Idea', 'Prototipo', 'MVP', 'Escalando'])  # Etapa del proyecto\n",
    "            asset_type = np.random.choice(['Equity', 'Deuda', 'Otro'])  # Tipo de activo tokenizado\n",
    "            asset_existing = np.random.choice([0, 1])  # Si el activo ya existe (binario)\n",
    "            legal_status = np.random.choice(['Regulado', 'No regulado'])  # Estado legal\n",
    "            impact_type = np.random.choice(['Social', 'Ambiental', 'Económico'])  # Tipo de impacto\n",
    "            \n",
    "            # Datos financieros aleatorios\n",
    "            estimated_total_cost = np.random.uniform(50000, 1000000)  # Costo estimado\n",
    "            funding_requested = np.random.uniform(10000, 500000)  # Financiación solicitada\n",
    "            expected_annual_revenue = np.random.uniform(20000, 2000000)  # Ingresos esperados anuales\n",
    "            \n",
    "            # Otros datos operativos\n",
    "            clients = np.random.choice([0, 1])  # Si tiene clientes o pilotos actualmente\n",
    "            scalability = np.random.randint(1, 6)  # Puntuación de escalabilidad (1-5)\n",
    "            \n",
    "            # Crear un registro completo para este ejemplo\n",
    "            row = {\n",
    "                'category': category,  # Categoría del proyecto\n",
    "                'stage': stage,        # Etapa de desarrollo\n",
    "                'summary': example['summary'],  # Texto de resumen del proyecto\n",
    "                'problem_addressed': example['problem_addressed'],  # Problema que aborda\n",
    "                'solution_proposed': example['solution_proposed'],  # Solución propuesta\n",
    "                'differentiation': example['differentiation'],  # Diferenciación competitiva\n",
    "                'tokenized_asset_type': asset_type,  # Tipo de activo tokenizado\n",
    "                'asset_existing': asset_existing,  # Existencia del activo\n",
    "                'legal_status': legal_status,  # Estado legal\n",
    "                'estimated_total_cost_eur': estimated_total_cost,  # Costo total estimado\n",
    "                'funding_requested_eur': funding_requested,  # Financiación solicitada\n",
    "                'expected_annual_revenue_eur': expected_annual_revenue,  # Ingresos anuales esperados\n",
    "                'current_clients_or_pilots': clients,  # Clientes actuales\n",
    "                'scalability_score': scalability,  # Puntuación de escalabilidad\n",
    "                'impact_type': impact_type  # Tipo de impacto\n",
    "            }\n",
    "            rows.append(row)  # Añadir este registro a la lista\n",
    "    \n",
    "    # Crear DataFrame con todos los ejemplos de validación\n",
    "    validation_data = pd.DataFrame(rows)\n",
    "    \n",
    "    # Aplicar el mismo preprocesamiento que se usó para los datos de entrenamiento\n",
    "    # Es crucial usar los mismos transformadores (encoder, scaler) que se ajustaron con los datos de entrenamiento\n",
    "    categorical_data = encoder.transform(validation_data[categorical_cols])  # Codificación one-hot\n",
    "    numeric_data = scaler.transform(validation_data[numeric_cols])  # Normalización\n",
    "    \n",
    "    # Procesar textos con BERT igual que en entrenamiento\n",
    "    text_data = []\n",
    "    for col in text_cols:\n",
    "        embeddings = get_bert_embeddings(validation_data[col].tolist())\n",
    "        text_data.append(embeddings)\n",
    "    text_data_combined = np.hstack(text_data)  # Combinar todos los embeddings de texto\n",
    "    \n",
    "    # Combinar todas las características en formato que el modelo pueda procesar\n",
    "    X_validation = np.hstack([\n",
    "        categorical_data,  # Variables categóricas codificadas\n",
    "        text_data_combined,  # Embeddings de texto\n",
    "        numeric_data,  # Variables numéricas normalizadas\n",
    "        validation_data[binary_cols].values  # Variables binarias\n",
    "    ])\n",
    "    \n",
    "    # Hacer predicciones con el modelo entrenado\n",
    "    predictions = model.predict(X_validation)\n",
    "    \n",
    "    # Añadir las predicciones al DataFrame de resultados\n",
    "    validation_data['predicted_viability'] = predictions\n",
    "    \n",
    "    # Calcular la puntuación \"real\" de viabilidad usando la misma fórmula que en el entrenamiento\n",
    "    # Esto nos da un punto de referencia para comparar con las predicciones\n",
    "    stage_score = validation_data['stage'].map({'Idea': 10, 'Prototipo': 20, 'MVP': 30, 'Escalando': 40})\n",
    "    client_score = validation_data['current_clients_or_pilots'] * 15\n",
    "    scalability_score = validation_data['scalability_score'] * 5\n",
    "    revenue_ratio = np.clip(validation_data['expected_annual_revenue_eur'] / (validation_data['estimated_total_cost_eur'] + 1), 0, 5) * 7\n",
    "    validation_data['actual_viability'] = np.clip(stage_score + client_score + scalability_score + revenue_ratio, 0, 100)\n",
    "    \n",
    "    return validation_data  # Devolver resultados de validación\n",
    "\n",
    "# Validar el modelo con los nuevos ejemplos\n",
    "validation_results = validate_model_with_new_examples(model, encoder, scaler, validation_examples)\n",
    "\n",
    "# Mostrar resultados de la validación\n",
    "print(\"\\nResultados de validación con ejemplos nuevos:\")\n",
    "print(validation_results[['category', 'summary', 'actual_viability', 'predicted_viability']].head())\n",
    "\n",
    "# Calcular métricas para los ejemplos de validación\n",
    "validation_mse = mean_squared_error(validation_results['actual_viability'], validation_results['predicted_viability'])\n",
    "validation_r2 = r2_score(validation_results['actual_viability'], validation_results['predicted_viability'])\n",
    "print(f\"\\nMSE en ejemplos de validación: {validation_mse:.2f}\")\n",
    "print(f\"R² en ejemplos de validación: {validation_r2:.2f}\")\n",
    "print(validation_results.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'stage', 'summary', 'problem_addressed',\n",
      "       'solution_proposed', 'differentiation', 'tokenized_asset_type',\n",
      "       'asset_existing', 'legal_status', 'estimated_total_cost_eur',\n",
      "       'funding_requested_eur', 'expected_annual_revenue_eur',\n",
      "       'current_clients_or_pilots', 'scalability_score', 'impact_type',\n",
      "       'predicted_viability', 'actual_viability'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 17 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   category                     8 non-null      object \n",
      " 1   stage                        8 non-null      object \n",
      " 2   summary                      8 non-null      object \n",
      " 3   problem_addressed            8 non-null      object \n",
      " 4   solution_proposed            8 non-null      object \n",
      " 5   differentiation              8 non-null      object \n",
      " 6   tokenized_asset_type         8 non-null      object \n",
      " 7   asset_existing               8 non-null      int64  \n",
      " 8   legal_status                 8 non-null      object \n",
      " 9   estimated_total_cost_eur     8 non-null      float64\n",
      " 10  funding_requested_eur        8 non-null      float64\n",
      " 11  expected_annual_revenue_eur  8 non-null      float64\n",
      " 12  current_clients_or_pilots    8 non-null      int64  \n",
      " 13  scalability_score            8 non-null      int64  \n",
      " 14  impact_type                  8 non-null      object \n",
      " 15  predicted_viability          8 non-null      float64\n",
      " 16  actual_viability             8 non-null      float64\n",
      "dtypes: float64(5), int64(3), object(9)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(validation_results.columns)\n",
    "print(validation_results.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando datos sintéticos...\n",
      "Datos generados: 500 ejemplos\n",
      "\n",
      "Entrenando modelo...\n",
      "MSE en entrenamiento: 47.43\n",
      "R² en entrenamiento: 0.85\n",
      "\n",
      "Características más importantes:\n",
      "feature_3088: 0.2102\n",
      "feature_3086: 0.1911\n",
      "feature_3: 0.1351\n",
      "feature_3089: 0.1225\n",
      "feature_3091: 0.1197\n",
      "feature_2: 0.1047\n",
      "feature_5: 0.0359\n",
      "feature_4: 0.0262\n",
      "feature_3087: 0.0231\n",
      "feature_7: 0.0042\n",
      "\n",
      "Generando datos de validación...\n",
      "Validando modelo...\n",
      "MSE en validación: 66.58\n",
      "R² en validación: 0.79\n",
      "\n",
      "Modelo guardado en: project_viability_model.pkl\n",
      "\n",
      "Cargando modelo guardado...\n",
      "Predicción de viabilidad para el proyecto ejemplo: 83.95/100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "\n",
    "class TextEmbedder:\n",
    "    \"\"\"\n",
    "    Clase para procesar texto utilizando modelos BERT y generar embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='bert-base-uncased', device=None):\n",
    "        \"\"\"\n",
    "        Inicializa el tokenizer y modelo BERT.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Nombre del modelo BERT preentrenado a utilizar\n",
    "            device: Dispositivo para ejecutar el modelo (None para autodetección)\n",
    "        \"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Autodetectar dispositivo si no se especifica\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()  # Establecer modo evaluación\n",
    "    \n",
    "    def get_embeddings(self, texts: List[str], max_length: int = 128) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convierte una lista de textos en embeddings utilizando BERT.\n",
    "        \n",
    "        Args:\n",
    "            texts: Lista de strings a procesar\n",
    "            max_length: Longitud máxima de tokens para cada texto\n",
    "            \n",
    "        Returns:\n",
    "            Array NumPy con los embeddings de los textos\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        # Mover inputs al dispositivo adecuado\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Extraer el vector [CLS] como representación del texto\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class ProjectViabilityModel:\n",
    "    \"\"\"\n",
    "    Modelo para predecir la viabilidad de proyectos utilizando características \n",
    "    textuales y numéricas.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el modelo y sus componentes de preprocesamiento.\"\"\"\n",
    "        self.text_embedder = TextEmbedder()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        \n",
    "        # Definir columnas para diferentes tipos de características\n",
    "        self.categorical_cols = ['category', 'stage', 'tokenized_asset_type', \n",
    "                                'legal_status', 'impact_type']\n",
    "        self.text_cols = ['summary', 'problem_addressed', \n",
    "                         'solution_proposed', 'differentiation']\n",
    "        self.numeric_cols = ['estimated_total_cost_eur', 'funding_requested_eur', \n",
    "                            'expected_annual_revenue_eur', 'scalability_score']\n",
    "        self.binary_cols = ['asset_existing', 'current_clients_or_pilots']\n",
    "        \n",
    "    def preprocess_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocesa los datos y extrae características para el modelo.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos a procesar\n",
    "            \n",
    "        Returns:\n",
    "            Tupla con (X, y) donde X son las características y y es la variable objetivo\n",
    "        \"\"\"\n",
    "        # Verificar que todas las columnas necesarias estén presentes\n",
    "        required_cols = (self.categorical_cols + self.text_cols + \n",
    "                         self.numeric_cols + self.binary_cols)\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Faltan columnas requeridas en los datos: {missing_cols}\")\n",
    "        \n",
    "        # Procesar variables categóricas\n",
    "        categorical_features = self.encoder.transform(data[self.categorical_cols])\n",
    "        \n",
    "        # Procesar variables textuales\n",
    "        text_features = []\n",
    "        for col in self.text_cols:\n",
    "            col_embeddings = self.text_embedder.get_embeddings(data[col].tolist())\n",
    "            text_features.append(col_embeddings)\n",
    "        text_features_combined = np.hstack(text_features)\n",
    "        \n",
    "        # Procesar variables numéricas\n",
    "        numeric_features = self.scaler.transform(data[self.numeric_cols])\n",
    "        \n",
    "        # Combinar todas las características\n",
    "        X = np.hstack([\n",
    "            categorical_features,\n",
    "            text_features_combined,\n",
    "            numeric_features,\n",
    "            data[self.binary_cols].values\n",
    "        ])\n",
    "        \n",
    "        # Variable objetivo (puede ser None si no está disponible)\n",
    "        y = data['viability_score'] if 'viability_score' in data.columns else None\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame, **model_params) -> Dict:\n",
    "        \"\"\"\n",
    "        Entrena el modelo con los datos proporcionados.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de entrenamiento\n",
    "            **model_params: Parámetros para el RandomForestRegressor\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con métricas de rendimiento del entrenamiento\n",
    "        \"\"\"\n",
    "        # Valores por defecto para los parámetros del modelo\n",
    "        default_params = {\n",
    "            'n_estimators': 200,\n",
    "            'max_depth': 15,\n",
    "            'min_samples_split': 5,\n",
    "            'min_samples_leaf': 2,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Actualizar con parámetros proporcionados\n",
    "        for key, value in model_params.items():\n",
    "            default_params[key] = value\n",
    "        \n",
    "        # Ajustar transformadores con todo el conjunto de datos\n",
    "        self.encoder.fit(data[self.categorical_cols])\n",
    "        self.scaler.fit(data[self.numeric_cols])\n",
    "        \n",
    "        # Preprocesar datos\n",
    "        X, y = self.preprocess_data(data)\n",
    "        \n",
    "        # Dividir en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Crear y entrenar el modelo\n",
    "        self.model = RandomForestRegressor(**default_params)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar el modelo\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Obtener importancia de características\n",
    "        feature_importances = self.model.feature_importances_\n",
    "        top_indices = np.argsort(feature_importances)[-10:]\n",
    "        top_importances = {f\"feature_{i}\": feature_importances[i] for i in reversed(top_indices)}\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'r2': r2,\n",
    "            'feature_importances': top_importances\n",
    "        }\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Realiza predicciones de viabilidad para nuevos proyectos.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de los proyectos a evaluar\n",
    "            \n",
    "        Returns:\n",
    "            Array con las predicciones de viabilidad\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"El modelo no ha sido entrenado. Llame al método fit() primero.\")\n",
    "        \n",
    "        # Preprocesar datos (ignorando la variable y si existe)\n",
    "        X, _ = self.preprocess_data(data)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def validate(self, validation_data: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida el modelo con un conjunto de datos de validación.\n",
    "        \n",
    "        Args:\n",
    "            validation_data: DataFrame con datos de validación\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con métricas y resultados de la validación\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"El modelo no ha sido entrenado. Llame al método fit() primero.\")\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        predictions = self.predict(validation_data)\n",
    "        \n",
    "        # Añadir predicciones al DataFrame\n",
    "        results_df = validation_data.copy()\n",
    "        results_df['predicted_viability'] = predictions\n",
    "        \n",
    "        # Si existe la columna de viabilidad real, calcular métricas\n",
    "        metrics = {}\n",
    "        if 'viability_score' in validation_data.columns:\n",
    "            mse = mean_squared_error(validation_data['viability_score'], predictions)\n",
    "            r2 = r2_score(validation_data['viability_score'], predictions)\n",
    "            metrics = {'mse': mse, 'r2': r2}\n",
    "        \n",
    "        return {\n",
    "            'results': results_df,\n",
    "            'metrics': metrics,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "    \n",
    "    def calculate_viability_score(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calcula una puntuación de viabilidad según la fórmula predefinida.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de los proyectos\n",
    "            \n",
    "        Returns:\n",
    "            Array con las puntuaciones de viabilidad calculadas\n",
    "        \"\"\"\n",
    "        # Factor 1: La etapa más avanzada aumenta la viabilidad\n",
    "        stage_score = data['stage'].map({'Idea': 10, 'Prototipo': 20, 'MVP': 30, 'Escalando': 40})\n",
    "        \n",
    "        # Factor 2: La existencia de clientes aumenta la viabilidad\n",
    "        client_score = data['current_clients_or_pilots'] * 15\n",
    "        \n",
    "        # Factor 3: Mayor escalabilidad aumenta la viabilidad\n",
    "        scalability_score = data['scalability_score'] * 5\n",
    "        \n",
    "        # Factor 4: Mejor ratio ingresos/costos aumenta la viabilidad\n",
    "        revenue_ratio = np.clip(data['expected_annual_revenue_eur'] / (data['estimated_total_cost_eur'] + 1), 0, 5) * 7\n",
    "        \n",
    "        # Calcular puntuación final\n",
    "        viability_score = stage_score + client_score + scalability_score + revenue_ratio\n",
    "        \n",
    "        # Limitar los valores entre 0 y 100\n",
    "        viability_score = np.clip(viability_score, 0, 100)\n",
    "        \n",
    "        return viability_score\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Guarda el modelo y sus componentes para uso futuro.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No hay modelo entrenado para guardar.\")\n",
    "        \n",
    "        model_data = {\n",
    "            'model': self.model,\n",
    "            'encoder': self.encoder,\n",
    "            'scaler': self.scaler,\n",
    "            'categorical_cols': self.categorical_cols,\n",
    "            'text_cols': self.text_cols,\n",
    "            'numeric_cols': self.numeric_cols,\n",
    "            'binary_cols': self.binary_cols\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str):\n",
    "        \"\"\"\n",
    "        Carga un modelo previamente guardado.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Ruta al archivo del modelo guardado\n",
    "            \n",
    "        Returns:\n",
    "            Instancia de ProjectViabilityModel con el modelo cargado\n",
    "        \"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        # Crear nueva instancia\n",
    "        instance = cls()\n",
    "        \n",
    "        # Cargar componentes\n",
    "        instance.model = model_data['model']\n",
    "        instance.encoder = model_data['encoder']\n",
    "        instance.scaler = model_data['scaler']\n",
    "        instance.categorical_cols = model_data['categorical_cols']\n",
    "        instance.text_cols = model_data['text_cols']\n",
    "        instance.numeric_cols = model_data['numeric_cols']\n",
    "        instance.binary_cols = model_data['binary_cols']\n",
    "        \n",
    "        return instance\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    \"\"\"\n",
    "    Clase para generar datos sintéticos de proyectos basados en ejemplos reales.\n",
    "    \"\"\"\n",
    "    def __init__(self, project_examples=None):\n",
    "        \"\"\"\n",
    "        Inicializa el generador de datos con ejemplos de proyectos.\n",
    "        \n",
    "        Args:\n",
    "            project_examples: Diccionario con ejemplos de proyectos por categoría\n",
    "        \"\"\"\n",
    "        # Usar los ejemplos proporcionados o los predeterminados\n",
    "        self.project_details = project_examples or self._get_default_examples()\n",
    "        \n",
    "        # Definir posibles valores para cada característica\n",
    "        self.categories = list(self.project_details.keys())\n",
    "        self.stages = ['Idea', 'Prototipo', 'MVP', 'Escalando']\n",
    "        self.asset_types = ['Equity', 'Deuda', 'Otro']\n",
    "        self.legal_statuses = ['Regulado', 'No regulado']\n",
    "        self.impact_types = ['Social', 'Ambiental', 'Económico']\n",
    "    \n",
    "    def _get_default_examples(self):\n",
    "        \"\"\"\n",
    "        Proporciona ejemplos predeterminados de proyectos si no se especifican.\n",
    "        \n",
    "        Returns:\n",
    "            Diccionario con ejemplos de proyectos por categoría\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Tech': [\n",
    "                {\n",
    "                    'summary': \"Plataforma de pagos transfronterizos que facilita la transferencia de dinero de manera rápida y segura.\",\n",
    "                    'problem_addressed': \"Los pagos internacionales son costosos y lentos, afectando a las pequeñas empresas.\",\n",
    "                    'solution_proposed': \"Solución que ofrece tarifas de pago transfronterizas reducidas y procesamiento rápido, utilizando blockchain.\",\n",
    "                    'differentiation': \"Utiliza una red de blockchain descentralizada para garantizar la transparencia y baja de costos en pagos.\"\n",
    "                },\n",
    "                # ... otros ejemplos\n",
    "            ],\n",
    "            'Energía': [\n",
    "                {\n",
    "                    'summary': \"Desarrollo de un sistema de energía solar de bajo costo para hogares en zonas rurales.\",\n",
    "                    'problem_addressed': \"El acceso a energía limpia en zonas rurales es limitado y costoso.\",\n",
    "                    'solution_proposed': \"Sistema de paneles solares con batería de almacenamiento que reduce el costo de energía en áreas rurales.\",\n",
    "                    'differentiation': \"Baterías solares desarrolladas con tecnología avanzada que optimizan la eficiencia en lugares remotos.\"\n",
    "                },\n",
    "                # ... otros ejemplos\n",
    "            ]\n",
    "            # ... otras categorías\n",
    "        }\n",
    "    \n",
    "    def generate_data(self, n: int = 500) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Genera un conjunto de datos sintéticos basados en ejemplos reales.\n",
    "        \n",
    "        Args:\n",
    "            n: Número de muestras a generar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame con datos sintéticos\n",
    "        \"\"\"\n",
    "        # Listas para almacenar los datos generados\n",
    "        category_list = []\n",
    "        summary_list = []\n",
    "        problem_list = []\n",
    "        solution_list = []\n",
    "        differentiation_list = []\n",
    "        \n",
    "        # Generar datos basados en ejemplos reales\n",
    "        for _ in range(n):\n",
    "            # Seleccionar una categoría aleatoria\n",
    "            category = np.random.choice(self.categories)\n",
    "            category_list.append(category)\n",
    "            \n",
    "            # Seleccionar un ejemplo aleatorio de esa categoría\n",
    "            example = random.choice(self.project_details[category])\n",
    "            \n",
    "            # Extraer textos del ejemplo\n",
    "            summary_list.append(example['summary'])\n",
    "            problem_list.append(example['problem_addressed'])\n",
    "            solution_list.append(example['solution_proposed'])\n",
    "            \n",
    "            # Verificar y extraer diferenciación si existe\n",
    "            if 'differentiation' in example:\n",
    "                differentiation_list.append(example['differentiation'])\n",
    "            else:\n",
    "                differentiation_list.append(\"Ventaja competitiva en el mercado\")\n",
    "        \n",
    "        # Crear DataFrame con todos los datos\n",
    "        data = pd.DataFrame({\n",
    "            'category': category_list,\n",
    "            'stage': np.random.choice(self.stages, n),\n",
    "            'summary': summary_list,\n",
    "            'problem_addressed': problem_list,\n",
    "            'solution_proposed': solution_list,\n",
    "            'differentiation': differentiation_list,\n",
    "            'tokenized_asset_type': np.random.choice(self.asset_types, n),\n",
    "            'asset_existing': np.random.choice([0, 1], n),\n",
    "            'legal_status': np.random.choice(self.legal_statuses, n),\n",
    "            'estimated_total_cost_eur': np.random.uniform(50000, 1000000, n),\n",
    "            'funding_requested_eur': np.random.uniform(10000, 500000, n),\n",
    "            'expected_annual_revenue_eur': np.random.uniform(20000, 2000000, n),\n",
    "            'current_clients_or_pilots': np.random.choice([0, 1], n),\n",
    "            'scalability_score': np.random.randint(1, 6, n),\n",
    "            'impact_type': np.random.choice(self.impact_types, n),\n",
    "        })\n",
    "        \n",
    "        # Añadir puntuación de viabilidad\n",
    "        model = ProjectViabilityModel()\n",
    "        data['viability_score'] = model.calculate_viability_score(data)\n",
    "        \n",
    "        # Añadir algo de ruido a la viabilidad\n",
    "        data['viability_score'] = data['viability_score'] + np.random.normal(0, 5, n)\n",
    "        data['viability_score'] = np.clip(data['viability_score'], 0, 100)\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplo de uso del sistema modular\n",
    "def main():\n",
    "    # 1. Generar datos de entrenamiento\n",
    "    print(\"Generando datos sintéticos...\")\n",
    "    data_gen = DataGenerator()\n",
    "    training_data = data_gen.generate_data(n=500)\n",
    "    print(f\"Datos generados: {training_data.shape[0]} ejemplos\")\n",
    "    \n",
    "    # 2. Crear y entrenar modelo\n",
    "    print(\"\\nEntrenando modelo...\")\n",
    "    model = ProjectViabilityModel()\n",
    "    training_metrics = model.fit(training_data)\n",
    "    \n",
    "    # 3. Mostrar métricas de entrenamiento\n",
    "    print(f\"MSE en entrenamiento: {training_metrics['mse']:.2f}\")\n",
    "    print(f\"R² en entrenamiento: {training_metrics['r2']:.2f}\")\n",
    "    \n",
    "    print(\"\\nCaracterísticas más importantes:\")\n",
    "    for feature, importance in training_metrics['feature_importances'].items():\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # 4. Generar datos para validación\n",
    "    print(\"\\nGenerando datos de validación...\")\n",
    "    validation_data = data_gen.generate_data(n=100)  # Menos ejemplos para validación\n",
    "    \n",
    "    # 5. Validar modelo con nuevos datos\n",
    "    print(\"Validando modelo...\")\n",
    "    validation_results = model.validate(validation_data)\n",
    "    \n",
    "    # 6. Mostrar métricas de validación\n",
    "    print(f\"MSE en validación: {validation_results['metrics']['mse']:.2f}\")\n",
    "    print(f\"R² en validación: {validation_results['metrics']['r2']:.2f}\")\n",
    "    \n",
    "    # 7. Guardar modelo para uso futuro\n",
    "    model_path = \"project_viability_model.pkl\"\n",
    "    model.save_model(model_path)\n",
    "    print(f\"\\nModelo guardado en: {model_path}\")\n",
    "    \n",
    "    # 8. Ejemplo de carga y uso del modelo guardado\n",
    "    print(\"\\nCargando modelo guardado...\")\n",
    "    loaded_model = ProjectViabilityModel.load_model(model_path)\n",
    "    \n",
    "    # 9. Crear un ejemplo específico para probar\n",
    "    example_project = {\n",
    "        'category': ['Tech'],\n",
    "        'stage': ['MVP'],\n",
    "        'summary': [\"Nueva plataforma de inteligencia artificial para optimización de procesos industriales\"],\n",
    "        'problem_addressed': [\"Los procesos industriales actuales son ineficientes y generan altos costos operativos\"],\n",
    "        'solution_proposed': [\"Software de IA que analiza procesos en tiempo real y recomienda optimizaciones\"],\n",
    "        'differentiation': [\"Algoritmos propietarios que reducen costos operativos en un 30% más que competidores\"],\n",
    "        'tokenized_asset_type': ['Equity'],\n",
    "        'asset_existing': [1],\n",
    "        'legal_status': ['Regulado'],\n",
    "        'estimated_total_cost_eur': [350000],\n",
    "        'funding_requested_eur': [200000],\n",
    "        'expected_annual_revenue_eur': [1200000],\n",
    "        'current_clients_or_pilots': [1],\n",
    "        'scalability_score': [5],\n",
    "        'impact_type': ['Económico']\n",
    "    }\n",
    "    example_df = pd.DataFrame(example_project)\n",
    "    \n",
    "    # 10. Predecir viabilidad del ejemplo\n",
    "    prediction = loaded_model.predict(example_df)[0]\n",
    "    print(f\"Predicción de viabilidad para el proyecto ejemplo: {prediction:.2f}/100\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando datos sintéticos...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicción de viabilidad para el proyecto ejemplo: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/100\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# 1. Generar datos de entrenamiento\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerando datos sintéticos...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     data_gen \u001b[38;5;241m=\u001b[39m \u001b[43mDataGenerator\u001b[49m()\n\u001b[0;32m      8\u001b[0m     training_data \u001b[38;5;241m=\u001b[39m data_gen\u001b[38;5;241m.\u001b[39mgenerate_data(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos generados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ejemplos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "# from model_modules import ProjectViabilityModel, DataGenerator, TextEmbedder\n",
    "\n",
    "# Ejemplo de uso del sistema modular\n",
    "def main():\n",
    "    # 1. Generar datos de entrenamiento\n",
    "    print(\"Generando datos sintéticos...\")\n",
    "    data_gen = DataGenerator()\n",
    "    training_data = data_gen.generate_data(n=500)\n",
    "    print(f\"Datos generados: {training_data.shape[0]} ejemplos\")\n",
    "    \n",
    "    # 2. Crear y entrenar modelo\n",
    "    print(\"\\nEntrenando modelo...\")\n",
    "    model = ProjectViabilityModel()\n",
    "    training_metrics = model.fit(training_data)\n",
    "    \n",
    "    # 3. Mostrar métricas de entrenamiento\n",
    "    print(f\"MSE en entrenamiento: {training_metrics['mse']:.2f}\")\n",
    "    print(f\"R² en entrenamiento: {training_metrics['r2']:.2f}\")\n",
    "    \n",
    "    print(\"\\nCaracterísticas más importantes:\")\n",
    "    for feature, importance in training_metrics['feature_importances'].items():\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # 4. Generar datos para validación\n",
    "    print(\"\\nGenerando datos de validación...\")\n",
    "    validation_data = data_gen.generate_data(n=100)  # Menos ejemplos para validación\n",
    "    \n",
    "    # 5. Validar modelo con nuevos datos\n",
    "    print(\"Validando modelo...\")\n",
    "    validation_results = model.validate(validation_data)\n",
    "    \n",
    "    # 6. Mostrar métricas de validación\n",
    "    print(f\"MSE en validación: {validation_results['metrics']['mse']:.2f}\")\n",
    "    print(f\"R² en validación: {validation_results['metrics']['r2']:.2f}\")\n",
    "    \n",
    "    # 7. Guardar modelo para uso futuro\n",
    "    model_path = \"project_viability_model.pkl\"\n",
    "    model.save_model(model_path)\n",
    "    print(f\"\\nModelo guardado en: {model_path}\")\n",
    "    \n",
    "    # 8. Ejemplo de carga y uso del modelo guardado\n",
    "    print(\"\\nCargando modelo guardado...\")\n",
    "    loaded_model = ProjectViabilityModel.load_model(model_path)\n",
    "    \n",
    "    # 9. Crear un ejemplo específico para probar\n",
    "    example_project = {\n",
    "        'category': ['Tech'],\n",
    "        'stage': ['MVP'],\n",
    "        'summary': [\"Nueva plataforma de inteligencia artificial para optimización de procesos industriales\"],\n",
    "        'problem_addressed': [\"Los procesos industriales actuales son ineficientes y generan altos costos operativos\"],\n",
    "        'solution_proposed': [\"Software de IA que analiza procesos en tiempo real y recomienda optimizaciones\"],\n",
    "        'differentiation': [\"Algoritmos propietarios que reducen costos operativos en un 30% más que competidores\"],\n",
    "        'tokenized_asset_type': ['Equity'],\n",
    "        'asset_existing': [1],\n",
    "        'legal_status': ['Regulado'],\n",
    "        'estimated_total_cost_eur': [350000],\n",
    "        'funding_requested_eur': [200000],\n",
    "        'expected_annual_revenue_eur': [1200000],\n",
    "        'current_clients_or_pilots': [1],\n",
    "        'scalability_score': [5],\n",
    "        'impact_type': ['Económico']\n",
    "    }\n",
    "    example_df = pd.DataFrame(example_project)\n",
    "    \n",
    "    # 10. Predecir viabilidad del ejemplo\n",
    "    prediction = loaded_model.predict(example_df)[0]\n",
    "    print(f\"Predicción de viabilidad para el proyecto ejemplo: {prediction:.2f}/100\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
