{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando datos sintéticos...\n",
      "Datos generados: 500 ejemplos\n",
      "\n",
      "Entrenando modelo...\n",
      "MSE en entrenamiento: 47.43\n",
      "R² en entrenamiento: 0.85\n",
      "\n",
      "Características más importantes:\n",
      "feature_3088: 0.2102\n",
      "feature_3086: 0.1911\n",
      "feature_3: 0.1351\n",
      "feature_3089: 0.1225\n",
      "feature_3091: 0.1197\n",
      "feature_2: 0.1047\n",
      "feature_5: 0.0359\n",
      "feature_4: 0.0262\n",
      "feature_3087: 0.0231\n",
      "feature_7: 0.0042\n",
      "\n",
      "Generando datos de validación...\n",
      "Validando modelo...\n",
      "MSE en validación: 66.58\n",
      "R² en validación: 0.79\n",
      "\n",
      "Modelo guardado en: project_viability_model.pkl\n",
      "\n",
      "Cargando modelo guardado...\n",
      "Predicción de viabilidad para el proyecto ejemplo: 83.95/100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "\n",
    "class TextEmbedder:\n",
    "    \"\"\"\n",
    "    Clase para procesar texto utilizando modelos BERT y generar embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='bert-base-uncased', device=None):\n",
    "        \"\"\"\n",
    "        Inicializa el tokenizer y modelo BERT.\n",
    "        \n",
    "        Args:\n",
    "            model_name: Nombre del modelo BERT preentrenado a utilizar\n",
    "            device: Dispositivo para ejecutar el modelo (None para autodetección)\n",
    "        \"\"\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Autodetectar dispositivo si no se especifica\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()  # Establecer modo evaluación\n",
    "    \n",
    "    def get_embeddings(self, texts: List[str], max_length: int = 128) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convierte una lista de textos en embeddings utilizando BERT.\n",
    "        \n",
    "        Args:\n",
    "            texts: Lista de strings a procesar\n",
    "            max_length: Longitud máxima de tokens para cada texto\n",
    "            \n",
    "        Returns:\n",
    "            Array NumPy con los embeddings de los textos\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            return_tensors='pt', \n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        # Mover inputs al dispositivo adecuado\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Extraer el vector [CLS] como representación del texto\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class ProjectViabilityModel:\n",
    "    \"\"\"\n",
    "    Modelo para predecir la viabilidad de proyectos utilizando características \n",
    "    textuales y numéricas.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el modelo y sus componentes de preprocesamiento.\"\"\"\n",
    "        self.text_embedder = TextEmbedder()\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        \n",
    "        # Definir columnas para diferentes tipos de características\n",
    "        self.categorical_cols = ['category', 'stage', 'tokenized_asset_type', \n",
    "                                'legal_status', 'impact_type']\n",
    "        self.text_cols = ['summary', 'problem_addressed', \n",
    "                         'solution_proposed', 'differentiation']\n",
    "        self.numeric_cols = ['estimated_total_cost_eur', 'funding_requested_eur', \n",
    "                            'expected_annual_revenue_eur', 'scalability_score']\n",
    "        self.binary_cols = ['asset_existing', 'current_clients_or_pilots']\n",
    "        \n",
    "    def preprocess_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocesa los datos y extrae características para el modelo.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos a procesar\n",
    "            \n",
    "        Returns:\n",
    "            Tupla con (X, y) donde X son las características y y es la variable objetivo\n",
    "        \"\"\"\n",
    "        # Verificar que todas las columnas necesarias estén presentes\n",
    "        required_cols = (self.categorical_cols + self.text_cols + \n",
    "                         self.numeric_cols + self.binary_cols)\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Faltan columnas requeridas en los datos: {missing_cols}\")\n",
    "        \n",
    "        # Procesar variables categóricas\n",
    "        categorical_features = self.encoder.transform(data[self.categorical_cols])\n",
    "        \n",
    "        # Procesar variables textuales\n",
    "        text_features = []\n",
    "        for col in self.text_cols:\n",
    "            col_embeddings = self.text_embedder.get_embeddings(data[col].tolist())\n",
    "            text_features.append(col_embeddings)\n",
    "        text_features_combined = np.hstack(text_features)\n",
    "        \n",
    "        # Procesar variables numéricas\n",
    "        numeric_features = self.scaler.transform(data[self.numeric_cols])\n",
    "        \n",
    "        # Combinar todas las características\n",
    "        X = np.hstack([\n",
    "            categorical_features,\n",
    "            text_features_combined,\n",
    "            numeric_features,\n",
    "            data[self.binary_cols].values\n",
    "        ])\n",
    "        \n",
    "        # Variable objetivo (puede ser None si no está disponible)\n",
    "        y = data['viability_score'] if 'viability_score' in data.columns else None\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame, **model_params) -> Dict:\n",
    "        \"\"\"\n",
    "        Entrena el modelo con los datos proporcionados.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de entrenamiento\n",
    "            **model_params: Parámetros para el RandomForestRegressor\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con métricas de rendimiento del entrenamiento\n",
    "        \"\"\"\n",
    "        # Valores por defecto para los parámetros del modelo\n",
    "        default_params = {\n",
    "            'n_estimators': 200,\n",
    "            'max_depth': 15,\n",
    "            'min_samples_split': 5,\n",
    "            'min_samples_leaf': 2,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Actualizar con parámetros proporcionados\n",
    "        for key, value in model_params.items():\n",
    "            default_params[key] = value\n",
    "        \n",
    "        # Ajustar transformadores con todo el conjunto de datos\n",
    "        self.encoder.fit(data[self.categorical_cols])\n",
    "        self.scaler.fit(data[self.numeric_cols])\n",
    "        \n",
    "        # Preprocesar datos\n",
    "        X, y = self.preprocess_data(data)\n",
    "        \n",
    "        # Dividir en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Crear y entrenar el modelo\n",
    "        self.model = RandomForestRegressor(**default_params)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar el modelo\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Obtener importancia de características\n",
    "        feature_importances = self.model.feature_importances_\n",
    "        top_indices = np.argsort(feature_importances)[-10:]\n",
    "        top_importances = {f\"feature_{i}\": feature_importances[i] for i in reversed(top_indices)}\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'r2': r2,\n",
    "            'feature_importances': top_importances\n",
    "        }\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Realiza predicciones de viabilidad para nuevos proyectos.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de los proyectos a evaluar\n",
    "            \n",
    "        Returns:\n",
    "            Array con las predicciones de viabilidad\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"El modelo no ha sido entrenado. Llame al método fit() primero.\")\n",
    "        \n",
    "        # Preprocesar datos (ignorando la variable y si existe)\n",
    "        X, _ = self.preprocess_data(data)\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def validate(self, validation_data: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida el modelo con un conjunto de datos de validación.\n",
    "        \n",
    "        Args:\n",
    "            validation_data: DataFrame con datos de validación\n",
    "            \n",
    "        Returns:\n",
    "            Diccionario con métricas y resultados de la validación\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"El modelo no ha sido entrenado. Llame al método fit() primero.\")\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        predictions = self.predict(validation_data)\n",
    "        \n",
    "        # Añadir predicciones al DataFrame\n",
    "        results_df = validation_data.copy()\n",
    "        results_df['predicted_viability'] = predictions\n",
    "        \n",
    "        # Si existe la columna de viabilidad real, calcular métricas\n",
    "        metrics = {}\n",
    "        if 'viability_score' in validation_data.columns:\n",
    "            mse = mean_squared_error(validation_data['viability_score'], predictions)\n",
    "            r2 = r2_score(validation_data['viability_score'], predictions)\n",
    "            metrics = {'mse': mse, 'r2': r2}\n",
    "        \n",
    "        return {\n",
    "            'results': results_df,\n",
    "            'metrics': metrics,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "    \n",
    "    def calculate_viability_score(self, data: pd.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calcula una puntuación de viabilidad según la fórmula predefinida.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos de los proyectos\n",
    "            \n",
    "        Returns:\n",
    "            Array con las puntuaciones de viabilidad calculadas\n",
    "        \"\"\"\n",
    "        # Factor 1: La etapa más avanzada aumenta la viabilidad\n",
    "        stage_score = data['stage'].map({'Idea': 10, 'Prototipo': 20, 'MVP': 30, 'Escalando': 40})\n",
    "        \n",
    "        # Factor 2: La existencia de clientes aumenta la viabilidad\n",
    "        client_score = data['current_clients_or_pilots'] * 15\n",
    "        \n",
    "        # Factor 3: Mayor escalabilidad aumenta la viabilidad\n",
    "        scalability_score = data['scalability_score'] * 5\n",
    "        \n",
    "        # Factor 4: Mejor ratio ingresos/costos aumenta la viabilidad\n",
    "        revenue_ratio = np.clip(data['expected_annual_revenue_eur'] / (data['estimated_total_cost_eur'] + 1), 0, 5) * 7\n",
    "        \n",
    "        # Calcular puntuación final\n",
    "        viability_score = stage_score + client_score + scalability_score + revenue_ratio\n",
    "        \n",
    "        # Limitar los valores entre 0 y 100\n",
    "        viability_score = np.clip(viability_score, 0, 100)\n",
    "        \n",
    "        return viability_score\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"Guarda el modelo y sus componentes para uso futuro.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"No hay modelo entrenado para guardar.\")\n",
    "        \n",
    "        model_data = {\n",
    "            'model': self.model,\n",
    "            'encoder': self.encoder,\n",
    "            'scaler': self.scaler,\n",
    "            'categorical_cols': self.categorical_cols,\n",
    "            'text_cols': self.text_cols,\n",
    "            'numeric_cols': self.numeric_cols,\n",
    "            'binary_cols': self.binary_cols\n",
    "        }\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath: str):\n",
    "        \"\"\"\n",
    "        Carga un modelo previamente guardado.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Ruta al archivo del modelo guardado\n",
    "            \n",
    "        Returns:\n",
    "            Instancia de ProjectViabilityModel con el modelo cargado\n",
    "        \"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        # Crear nueva instancia\n",
    "        instance = cls()\n",
    "        \n",
    "        # Cargar componentes\n",
    "        instance.model = model_data['model']\n",
    "        instance.encoder = model_data['encoder']\n",
    "        instance.scaler = model_data['scaler']\n",
    "        instance.categorical_cols = model_data['categorical_cols']\n",
    "        instance.text_cols = model_data['text_cols']\n",
    "        instance.numeric_cols = model_data['numeric_cols']\n",
    "        instance.binary_cols = model_data['binary_cols']\n",
    "        \n",
    "        return instance\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    \"\"\"\n",
    "    Clase para generar datos sintéticos de proyectos basados en ejemplos reales.\n",
    "    \"\"\"\n",
    "    def __init__(self, project_examples=None):\n",
    "        \"\"\"\n",
    "        Inicializa el generador de datos con ejemplos de proyectos.\n",
    "        \n",
    "        Args:\n",
    "            project_examples: Diccionario con ejemplos de proyectos por categoría\n",
    "        \"\"\"\n",
    "        # Usar los ejemplos proporcionados o los predeterminados\n",
    "        self.project_details = project_examples or self._get_default_examples()\n",
    "        \n",
    "        # Definir posibles valores para cada característica\n",
    "        self.categories = list(self.project_details.keys())\n",
    "        self.stages = ['Idea', 'Prototipo', 'MVP', 'Escalando']\n",
    "        self.asset_types = ['Equity', 'Deuda', 'Otro']\n",
    "        self.legal_statuses = ['Regulado', 'No regulado']\n",
    "        self.impact_types = ['Social', 'Ambiental', 'Económico']\n",
    "    \n",
    "    def _get_default_examples(self):\n",
    "        \"\"\"\n",
    "        Proporciona ejemplos predeterminados de proyectos si no se especifican.\n",
    "        \n",
    "        Returns:\n",
    "            Diccionario con ejemplos de proyectos por categoría\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Tech': [\n",
    "                {\n",
    "                    'summary': \"Plataforma de pagos transfronterizos que facilita la transferencia de dinero de manera rápida y segura.\",\n",
    "                    'problem_addressed': \"Los pagos internacionales son costosos y lentos, afectando a las pequeñas empresas.\",\n",
    "                    'solution_proposed': \"Solución que ofrece tarifas de pago transfronterizas reducidas y procesamiento rápido, utilizando blockchain.\",\n",
    "                    'differentiation': \"Utiliza una red de blockchain descentralizada para garantizar la transparencia y baja de costos en pagos.\"\n",
    "                },\n",
    "                # ... otros ejemplos\n",
    "            ],\n",
    "            'Energía': [\n",
    "                {\n",
    "                    'summary': \"Desarrollo de un sistema de energía solar de bajo costo para hogares en zonas rurales.\",\n",
    "                    'problem_addressed': \"El acceso a energía limpia en zonas rurales es limitado y costoso.\",\n",
    "                    'solution_proposed': \"Sistema de paneles solares con batería de almacenamiento que reduce el costo de energía en áreas rurales.\",\n",
    "                    'differentiation': \"Baterías solares desarrolladas con tecnología avanzada que optimizan la eficiencia en lugares remotos.\"\n",
    "                },\n",
    "                # ... otros ejemplos\n",
    "            ]\n",
    "            # ... otras categorías\n",
    "        }\n",
    "    \n",
    "    def generate_data(self, n: int = 500) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Genera un conjunto de datos sintéticos basados en ejemplos reales.\n",
    "        \n",
    "        Args:\n",
    "            n: Número de muestras a generar\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame con datos sintéticos\n",
    "        \"\"\"\n",
    "        # Listas para almacenar los datos generados\n",
    "        category_list = []\n",
    "        summary_list = []\n",
    "        problem_list = []\n",
    "        solution_list = []\n",
    "        differentiation_list = []\n",
    "        \n",
    "        # Generar datos basados en ejemplos reales\n",
    "        for _ in range(n):\n",
    "            # Seleccionar una categoría aleatoria\n",
    "            category = np.random.choice(self.categories)\n",
    "            category_list.append(category)\n",
    "            \n",
    "            # Seleccionar un ejemplo aleatorio de esa categoría\n",
    "            example = random.choice(self.project_details[category])\n",
    "            \n",
    "            # Extraer textos del ejemplo\n",
    "            summary_list.append(example['summary'])\n",
    "            problem_list.append(example['problem_addressed'])\n",
    "            solution_list.append(example['solution_proposed'])\n",
    "            \n",
    "            # Verificar y extraer diferenciación si existe\n",
    "            if 'differentiation' in example:\n",
    "                differentiation_list.append(example['differentiation'])\n",
    "            else:\n",
    "                differentiation_list.append(\"Ventaja competitiva en el mercado\")\n",
    "        \n",
    "        # Crear DataFrame con todos los datos\n",
    "        data = pd.DataFrame({\n",
    "            'category': category_list,\n",
    "            'stage': np.random.choice(self.stages, n),\n",
    "            'summary': summary_list,\n",
    "            'problem_addressed': problem_list,\n",
    "            'solution_proposed': solution_list,\n",
    "            'differentiation': differentiation_list,\n",
    "            'tokenized_asset_type': np.random.choice(self.asset_types, n),\n",
    "            'asset_existing': np.random.choice([0, 1], n),\n",
    "            'legal_status': np.random.choice(self.legal_statuses, n),\n",
    "            'estimated_total_cost_eur': np.random.uniform(50000, 1000000, n),\n",
    "            'funding_requested_eur': np.random.uniform(10000, 500000, n),\n",
    "            'expected_annual_revenue_eur': np.random.uniform(20000, 2000000, n),\n",
    "            'current_clients_or_pilots': np.random.choice([0, 1], n),\n",
    "            'scalability_score': np.random.randint(1, 6, n),\n",
    "            'impact_type': np.random.choice(self.impact_types, n),\n",
    "        })\n",
    "        \n",
    "        # Añadir puntuación de viabilidad\n",
    "        model = ProjectViabilityModel()\n",
    "        data['viability_score'] = model.calculate_viability_score(data)\n",
    "        \n",
    "        # Añadir algo de ruido a la viabilidad\n",
    "        data['viability_score'] = data['viability_score'] + np.random.normal(0, 5, n)\n",
    "        data['viability_score'] = np.clip(data['viability_score'], 0, 100)\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplo de uso del sistema modular\n",
    "def main():\n",
    "    # 1. Generar datos de entrenamiento\n",
    "    print(\"Generando datos sintéticos...\")\n",
    "    data_gen = DataGenerator()\n",
    "    training_data = data_gen.generate_data(n=500)\n",
    "    print(f\"Datos generados: {training_data.shape[0]} ejemplos\")\n",
    "    \n",
    "    # 2. Crear y entrenar modelo\n",
    "    print(\"\\nEntrenando modelo...\")\n",
    "    model = ProjectViabilityModel()\n",
    "    training_metrics = model.fit(training_data)\n",
    "    \n",
    "    # 3. Mostrar métricas de entrenamiento\n",
    "    print(f\"MSE en entrenamiento: {training_metrics['mse']:.2f}\")\n",
    "    print(f\"R² en entrenamiento: {training_metrics['r2']:.2f}\")\n",
    "    \n",
    "    print(\"\\nCaracterísticas más importantes:\")\n",
    "    for feature, importance in training_metrics['feature_importances'].items():\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # 4. Generar datos para validación\n",
    "    print(\"\\nGenerando datos de validación...\")\n",
    "    validation_data = data_gen.generate_data(n=100)  # Menos ejemplos para validación\n",
    "    \n",
    "    # 5. Validar modelo con nuevos datos\n",
    "    print(\"Validando modelo...\")\n",
    "    validation_results = model.validate(validation_data)\n",
    "    \n",
    "    # 6. Mostrar métricas de validación\n",
    "    print(f\"MSE en validación: {validation_results['metrics']['mse']:.2f}\")\n",
    "    print(f\"R² en validación: {validation_results['metrics']['r2']:.2f}\")\n",
    "    \n",
    "    # 7. Guardar modelo para uso futuro\n",
    "    model_path = \"project_viability_model.pkl\"\n",
    "    model.save_model(model_path)\n",
    "    print(f\"\\nModelo guardado en: {model_path}\")\n",
    "    \n",
    "    # 8. Ejemplo de carga y uso del modelo guardado\n",
    "    print(\"\\nCargando modelo guardado...\")\n",
    "    loaded_model = ProjectViabilityModel.load_model(model_path)\n",
    "    \n",
    "    # 9. Crear un ejemplo específico para probar\n",
    "    example_project = {\n",
    "        'category': ['Tech'],\n",
    "        'stage': ['MVP'],\n",
    "        'summary': [\"Nueva plataforma de inteligencia artificial para optimización de procesos industriales\"],\n",
    "        'problem_addressed': [\"Los procesos industriales actuales son ineficientes y generan altos costos operativos\"],\n",
    "        'solution_proposed': [\"Software de IA que analiza procesos en tiempo real y recomienda optimizaciones\"],\n",
    "        'differentiation': [\"Algoritmos propietarios que reducen costos operativos en un 30% más que competidores\"],\n",
    "        'tokenized_asset_type': ['Equity'],\n",
    "        'asset_existing': [1],\n",
    "        'legal_status': ['Regulado'],\n",
    "        'estimated_total_cost_eur': [350000],\n",
    "        'funding_requested_eur': [200000],\n",
    "        'expected_annual_revenue_eur': [1200000],\n",
    "        'current_clients_or_pilots': [1],\n",
    "        'scalability_score': [5],\n",
    "        'impact_type': ['Económico']\n",
    "    }\n",
    "    example_df = pd.DataFrame(example_project)\n",
    "    \n",
    "    # 10. Predecir viabilidad del ejemplo\n",
    "    prediction = loaded_model.predict(example_df)[0]\n",
    "    print(f\"Predicción de viabilidad para el proyecto ejemplo: {prediction:.2f}/100\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
